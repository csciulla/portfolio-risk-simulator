{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csciulla/stress-test-dashboard/blob/main/stresstest_ntbk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLI8WY6CEmZc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from hmmlearn.hmm import GaussianHMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqxxkxH4FMGT"
      },
      "outputs": [],
      "source": [
        "class Portfolio:\n",
        "  def __init__(self, portfolio:list,  lower_bound:float, upper_bound:float):\n",
        "    try:\n",
        "      if lower_bound >= upper_bound:\n",
        "        raise ValueError(\"Lower bound must be less than upper bound.\")\n",
        "\n",
        "      self.portfolio = portfolio\n",
        "      self.weights = None\n",
        "      self.dfclose = None\n",
        "      self.lower_bound = lower_bound\n",
        "      self.upper_bound = upper_bound\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in intializer function: {e}\")\n",
        "      return None\n",
        "\n",
        "  def get_data(self, period:str=None, start_date:str=None, end_date:str=None):\n",
        "    \"\"\"\n",
        "    Downloads the portfolios adjusted closes either by 'period' or 'start_date' and 'end_date'.\n",
        "    Only one method of date input should be provided.\n",
        "    Data downloaded should be big enough to handle calculations.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if period and (start_date or end_date): #checks if both methods of date input are used\n",
        "        raise ValueError(\"Provide either 'period' OR both 'start_date' and 'end_date' -- not both.\")\n",
        "\n",
        "      if period:\n",
        "        period = period.strip()\n",
        "        self.dfclose = yf.download(self.portfolio, period=period, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "      elif start_date and end_date:\n",
        "        start_date = start_date.strip()\n",
        "        end_date = end_date.strip()\n",
        "        self.dfclose = yf.download(self.portfolio, start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "      else:\n",
        "        raise ValueError(\"You must provide either a 'period' or both 'start_date' and 'end_date'.\")\n",
        "\n",
        "      if self.dfclose.empty or self.dfclose is None:\n",
        "        raise ValueError(\"Downloaded price data is empty or unavailable.\")\n",
        "      elif len(self.dfclose) <= 2:\n",
        "        raise ValueError(\"Downloaded price data is too short.\")\n",
        "      elif len(self.dfclose) < 21: #average trading days in a month\n",
        "        print(\"Warning: Limited price history may lead to unreliable metrics.\")\n",
        "\n",
        "      return self.dfclose\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in get_data: {e}\")\n",
        "      return None\n",
        "\n",
        "  def get_weights(self, type_weight:str):\n",
        "    \"\"\"\n",
        "    Returns a list of weights for the portfolio.\n",
        "\n",
        "    type_weight: Input 'eq' for equal-weighted portfolio or 'opt' for optimized weights based on sharpe-ratio\n",
        "    \"\"\"\n",
        "    try:\n",
        "      dfclose = self.dfclose\n",
        "      if dfclose is None or dfclose.empty:\n",
        "        raise ValueError(\"The portfolio's price data is missing. Please properly run 'get_data' first.\")\n",
        "      elif len(dfclose) <= 2:\n",
        "        raise ValueError(\"Downloaded price data is too short.\")\n",
        "\n",
        "      #Get log returns of each asset\n",
        "      log_returns = np.log(dfclose/dfclose.shift()).dropna()\n",
        "\n",
        "      #Calculate initial portfolio metrics\n",
        "      weights = np.repeat(1/len(self.portfolio), len(self.portfolio))\n",
        "      expected_returns = log_returns.mean()*252\n",
        "      port_returns = weights.T @ expected_returns\n",
        "      cov_matrix = log_returns.cov()*252\n",
        "      port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
        "      rf = 0.045\n",
        "\n",
        "      #Set bounds and constraints for objective function\n",
        "      bounds = [(self.lower_bound, self.upper_bound) for _ in range(len(self.portfolio))]\n",
        "      constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w)-1}\n",
        "      def neg_sharpe(w):\n",
        "        port_ret = w.T @ expected_returns\n",
        "        port_std = np.sqrt(w.T @ cov_matrix @ w)\n",
        "        return -((port_ret - rf)/port_std)\n",
        "\n",
        "      if type_weight.strip().lower() == \"eq\":\n",
        "        self.weights = [float(i) for i in weights]\n",
        "      elif type_weight.strip().lower() == \"opt\":\n",
        "        optimized_weights = minimize(neg_sharpe, weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "        self.weights = [round(float(i),4) for i in optimized_weights.x]\n",
        "      else:\n",
        "        raise ValueError(\"Select a valid input for 'type_weight' -- either 'eq' or 'opt'.\")\n",
        "\n",
        "      return self.weights\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in get_weights: {e}\")\n",
        "      return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPonahsNZiJ",
        "outputId": "64abc5c7-a2ca-43e2-f7ff-9d3206b7cf88"
      },
      "outputs": [],
      "source": [
        "#test weights\n",
        "test = Portfolio(['AAPL','AMZN','META','GOOG'], 0.0, 0.5)\n",
        "test.get_data('5y')\n",
        "test.get_weights(\"opt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz7s7C0VPA00"
      },
      "outputs": [],
      "source": [
        "def monte_carlo(T:int, sims:int, weights:list, df:pd.DataFrame, regime:str, level:str, rand:str=None ):\n",
        "  \"\"\"\n",
        "  Returns simulated prices for each ticker in the portfolio using Monte Carlo Simulation.\n",
        "\n",
        "  T: number of days in a path\n",
        "  sims: number of paths\n",
        "  weights: list of asset weights\n",
        "  df: dataframe of the assets adjusted closes\n",
        "  regime: determines how much or how little the portfolio is affected by the crisis event    \n",
        "  level: scale of the crisis event\n",
        "  rand: input the string 'yes' to return a random path, otherwise ignore\n",
        "\n",
        "  regime options: 'Low', 'Medium', 'High'\n",
        "  level options: 'Mild', 'Moderate', 'Severe', 'Tail Risk', 'Regulatory'\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if T <= 2:\n",
        "      raise ValueError(\"The length of each simulated path is too short.\")\n",
        "    elif T < 21:\n",
        "      print(\"Warning: Limited price data may lead to unreliable metrics.\")\n",
        "\n",
        "    #Intialize dictionary to store simulated paths of T days for each ticker\n",
        "    tickers = list(df.columns)\n",
        "    sims_returns = {ticker: np.full(shape=(T, sims), fill_value=0.0) for ticker in tickers}\n",
        "    \n",
        "    #Correspond regime with scaling factor\n",
        "    regime = regime.strip().capitalize()\n",
        "    level = level.strip().capitalize()\n",
        "    factorDict = {\"Mild\": 0.8,\n",
        "                  \"Moderate\": 1.2,\n",
        "                  \"Severe\": 1.7,\n",
        "                  \"Tail Risk\": 2.0,\n",
        "                  \"Regulatory\": 2.5}\n",
        "    scaling_factor = factorDict[level]\n",
        "\n",
        "    #Gather log returns from historical data\n",
        "    log_returns = np.log(df/df.shift()).dropna()\n",
        "\n",
        "    #Create mean matrix \n",
        "    expected_return = log_returns.mean()\n",
        "    meanM = np.full(shape=(T, len(tickers)), fill_value=expected_return)\n",
        "\n",
        "    #Initalize HMM\n",
        "    port_returns = (log_returns @ weights).values.reshape(-1,1) #HMM requires 2D array\n",
        "    historical_port_vol = np.std(port_returns)\n",
        "    model = GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=1000, random_state=42)\n",
        "    model.fit(port_returns)\n",
        "\n",
        "    #Gather the volatility regimes established by the HMM and correspond them with their respective state\n",
        "    vol_states = [\"Low\",\"Medium\",\"High\"]\n",
        "    vol_regimes = np.sqrt([var[0][0] for var in model.covars_])\n",
        "    vol_regimes = np.sort(vol_regimes)\n",
        "    vol_dict = {state: vol for state, vol in zip(vol_states, vol_regimes)}\n",
        "\n",
        "    #Calculate the scale factor needed for the historical data to reach the desired volatility and then apply it to L\n",
        "    desired_vol = vol_dict[regime]*scaling_factor\n",
        "    vol_scale_factor = desired_vol / historical_port_vol\n",
        "    cov_matrix = log_returns.cov()* (vol_scale_factor**2)\n",
        "    L = np.linalg.cholesky(cov_matrix)\n",
        "\n",
        "    #Generate paths\n",
        "    for m in range(sims):\n",
        "      Z = np.random.normal(size=(T, len(tickers)))\n",
        "      dailyReturns = meanM + Z @ L.T\n",
        "      for i, ticker in enumerate(tickers):\n",
        "        sims_returns[ticker][:,m] = dailyReturns[:,i]\n",
        "\n",
        "    #Get a random path\n",
        "    if isinstance(rand, str) and rand.strip().lower() == \"yes\":\n",
        "      random_int = np.random.randint(0,sims)\n",
        "      random_sims_returns = {ticker: sims_returns[ticker][:,random_int] for ticker in tickers}\n",
        "      random_sims_df = pd.DataFrame(random_sims_returns)\n",
        "      return random_sims_df\n",
        "    elif rand != None:\n",
        "      raise ValueError(\"Invaild input for 'rand'. Input the string 'yes' to return a random path, otherwise ignore.\")\n",
        "    else:\n",
        "        return sims_returns\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in monte_carlo: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = test.get_data('5y')\n",
        "monte_carlo(T=25, sims=5, weights=[0.353, 0.0, 0.4469, 0.2001], df=df, regime=\"Low\", level='Mild')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBjYP6uUOuJy"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(weights:list, df:pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Calculates annual portfolio volatilty, Sharpe Ratio, 95% VaR, Max Drawdown, and Beta.\n",
        "  weights: list of each assets weight in the portfolio\n",
        "  df: dataframe of the assets adjusted closes or simulated log_returns\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if df is None or df.empty:\n",
        "      raise ValueError(\"Price data is empty or unavailable. Make sure historical/simulated data is properly downloaded.\")\n",
        "\n",
        "    #Core calculations\n",
        "    if df.iloc[0,0] < 1:\n",
        "      log_returns = df\n",
        "    else:\n",
        "      log_returns = np.log(df/df.shift()).dropna()\n",
        "\n",
        "    tickers = list(df.columns)\n",
        "    weights = np.array(weights)\n",
        "    expected_returns = log_returns.mean()*252\n",
        "    cov_matrix = log_returns.cov()*252\n",
        "    rf = 0.045\n",
        "    port_returns = weights.T @ expected_returns\n",
        "    port_returns_series = log_returns @ weights\n",
        "\n",
        "    #Metrics\n",
        "    port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
        "    sharpe = (port_returns - rf)/port_vol\n",
        "    VaR_95 = np.percentile(port_returns_series, 5)\n",
        "\n",
        "    #Max Drawdown\n",
        "    cum_returns = (1+port_returns_series).cumprod()\n",
        "    cum_max = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = cum_returns/cum_max - 1\n",
        "    mdd = drawdown.min() #drawdown values are negative\n",
        "\n",
        "    #Beta\n",
        "    market = yf.download(\"SPY\", period='10y', progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "    market_returns = (np.log(market/market.shift()).dropna()).squeeze() #convert to series so that it works properly with port_returns_series\n",
        "    if pd.api.types.is_integer_dtype(port_returns_series.index):\n",
        "      #Simulated case: align by length\n",
        "      market_returns = market_returns.tail(len(port_returns_series)).reset_index(drop=True)\n",
        "      port_returns_series = port_returns_series.reset_index(drop=True)\n",
        "    else:\n",
        "      #Simulated historical case: align by date\n",
        "      start_date = pd.to_datetime(port_returns_series.index[0])\n",
        "      end_date = pd.to_datetime(port_returns_series.index[-1])\n",
        "      if start_date and end_date not in market_returns.index: #first make sure that market data contains crisis event\n",
        "        market = yf.download(\"SPY\", start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "        market_returns = (np.log(market/market.shift()).dropna()).squeeze()\n",
        "\n",
        "      #align by date for either simulated historical or historical case\n",
        "      aligned_index = port_returns_series.index.intersection(market_returns.index)\n",
        "      market_returns = market_returns.loc[aligned_index]\n",
        "      port_returns_series = port_returns_series.loc[aligned_index]\n",
        "    beta = port_returns_series.cov(market_returns) / market_returns.var()\n",
        "\n",
        "    #Calculate PCR\n",
        "    PCRdict = {}\n",
        "    for i, ticker in enumerate(tickers):\n",
        "      ticker_vol = np.std(log_returns[ticker]) * np.sqrt(252)\n",
        "      ticker_corr = log_returns[ticker].corr(port_returns_series)\n",
        "      MRC = ticker_vol*ticker_corr\n",
        "      PCR = (weights[i]*MRC)/port_vol\n",
        "      PCRdict[ticker] = (f\"{PCR*100:.2f}%\")\n",
        "    PCRframe = pd.DataFrame(data=PCRdict, index=[\"PCR\"])\n",
        "\n",
        "    metrics = pd.DataFrame(data=[[port_vol, sharpe, VaR_95, mdd, beta]] ,columns=[\"Annual Volatilty\", \"Sharpe\",\"95% VaR\", \"Max DD\", \"Beta\"], index=[\"Portfolio\"])\n",
        "    return metrics, PCRframe\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in calculate_metrics: {e}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = test.get_data('5y')\n",
        "calculate_metrics([0.353, 0.0, 0.4469, 0.2001], df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 326,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPEDH1CnO54O",
        "outputId": "d87de544-986b-4ba1-fea5-9e7f73836edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Annual Volatilty    Sharpe   95% VaR    Max DD      Beta\n",
            "Worst Portfolio          0.482914  0.079688 -0.048495 -0.464796  0.145083\n",
            "       AAPL   AMZN    GOOG    META\n",
            "PCR  33.96%  0.00%  42.50%  23.44%\n",
            "                Annual Volatilty    Sharpe  95% VaR    Max DD      Beta\n",
            "Best Portfolio          0.575694  0.221545 -0.05984 -0.537725 -0.227449\n",
            "       AAPL   AMZN    GOOG    META\n",
            "PCR  33.94%  0.00%  42.44%  23.53%\n"
          ]
        }
      ],
      "source": [
        "#test the simulated max and min sharpe metrics\n",
        "df = test.get_data('10y')\n",
        "mc = monte_carlo(504,50,[0.353, 0.0, 0.4469, 0.2001], df, regime=\"High\", level='Moderate')\n",
        "tickers = list(df.columns)\n",
        "sims = len(mc[tickers[0]][0])\n",
        "all_metrics = []\n",
        "all_PCR = []\n",
        "for m in range(sims):\n",
        "  mth_df = pd.DataFrame({ticker: mc[ticker][:,m] for ticker in tickers})\n",
        "  metrics = calculate_metrics([0.353, 0.0, 0.4469, 0.2001], mth_df)\n",
        "  all_metrics.append(metrics[0])\n",
        "  all_PCR.append(metrics[1])\n",
        "sharpes = [df.loc[\"Portfolio\", \"Annual Volatilty\"] for df in all_metrics]\n",
        "min_idx = np.argmin(sharpes)\n",
        "max_idx = np.argmax(sharpes)\n",
        "all_metrics[min_idx].index = [\"Worst Portfolio\"]\n",
        "all_metrics[max_idx].index = [\"Best Portfolio\"]\n",
        "print(all_metrics[min_idx])\n",
        "print(all_PCR[min_idx])\n",
        "print(all_metrics[max_idx])\n",
        "print(all_PCR[max_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhhEAq3-SESm"
      },
      "outputs": [],
      "source": [
        "def historical(df:pd.DataFrame, crisis:str):\n",
        "  \"\"\"\n",
        "  Simulates the prices of your portfolio if a historical event were to happen again.\n",
        "\n",
        "  df: dataframe of the assets adjusted closes\n",
        "  crisis: string of the event you want to simulate\n",
        "\n",
        "  Crisis Options:\n",
        "  \"DOT-COM\" -- The Dot-Com bubble\n",
        "  \"2008 GFC\" -- 2008 Global Financial Crisis\n",
        "  \"2011 Euro\" -- 2011 Eurozone Crisis\n",
        "  \"COVID\" -- COVID-19 Pandemic\n",
        "  \"2022 Inf\" -- 2022 Inflation Crash\n",
        "  \"\"\"\n",
        "  try:\n",
        "    crisis_periods = {\"DOT-COM\": (\"2000-03-01\", \"2002-10-01\"),\n",
        "                      \"2008 GFC\": (\"2007-10-01\", \"2009-03-01\"),\n",
        "                      \"2011 Euro\": (\"2011-07-01\", \"2011-12-01\"),\n",
        "                      \"COVID\": (\"2020-02-14\", \"2020-04-15\"),\n",
        "                      \"2022 Inf\": (\"2022-01-01\", \"2022-10-01\")\n",
        "                      }\n",
        "    crisis = crisis.strip()\n",
        "    if crisis not in crisis_periods.keys():\n",
        "      raise ValueError(\"Input a valid crisis event.\")\n",
        "\n",
        "    tickers = list(df.columns)\n",
        "    start_date = pd.to_datetime(crisis_periods[crisis][0])\n",
        "    end_date = pd.to_datetime(crisis_periods[crisis][1])\n",
        "\n",
        "    if start_date not in df.index: #check if crisis event does not exist in existing df\n",
        "      dfcrisis = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "    else:\n",
        "      dfcrisis = df.loc[start_date:end_date]\n",
        "\n",
        "    for ticker in tickers:\n",
        "      if dfcrisis[ticker].isna().sum() >= len(dfcrisis[ticker])//3: #checks if any ticker reaches NA threshold\n",
        "        raise ValueError(f\"{ticker} price data does not exist for crisis period.\")\n",
        "\n",
        "    last_price = df.iloc[-1]\n",
        "    crisisReturns = np.log(dfcrisis/dfcrisis.shift()).dropna()\n",
        "    cumReturns = (1+crisisReturns).cumprod()\n",
        "    crisisPrices = last_price.mul(cumReturns)\n",
        "    return crisisPrices\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\" \\n Error in historical: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "B-qNv5CHoCLc",
        "outputId": "bb59e533-9814-4e1b-fff4-ca13596e8713"
      },
      "outputs": [],
      "source": [
        "df = yf.download([\"AAPL\", \"MSFT\", \"GOOG\", \"JNJ\", \"XOM\"], period='10y', auto_adjust=False)[\"Adj Close\"]\n",
        "hist = historical(df, \"COVID\")\n",
        "calculate_metrics([0.0, 0.056, 0.0, 0.444, 0.5], hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDzH-XvNcDxV",
        "outputId": "2fb61a85-ce7e-4fc8-e8bd-11ea7fb521de"
      },
      "outputs": [],
      "source": [
        "[s.strip() for s in \"'2020-01-01', '2025-01-01'\".split(',')]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMjeGxU8gQJHS+IGNW8Vz1s",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
