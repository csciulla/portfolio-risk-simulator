{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csciulla/stress-test-dashboard/blob/main/stresstest_ntbk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cLI8WY6CEmZc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yfinance as yf\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from scipy.optimize import minimize\n",
        "from hmmlearn.hmm import GaussianHMM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqxxkxH4FMGT"
      },
      "outputs": [],
      "source": [
        "class Portfolio:\n",
        "  def __init__(self, portfolio:list,  lower_bound:float, upper_bound:float):\n",
        "    try:\n",
        "      if lower_bound >= upper_bound:\n",
        "        raise ValueError(\"Lower bound must be less than upper bound.\")\n",
        "\n",
        "      self.portfolio = portfolio\n",
        "      self.weights = None\n",
        "      self.dfclose = None\n",
        "      self.lower_bound = lower_bound\n",
        "      self.upper_bound = upper_bound\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in intializer function: {e}\")\n",
        "      return None\n",
        "\n",
        "  def get_data(self, period:str=None, start_date:str=None, end_date:str=None):\n",
        "    \"\"\"\n",
        "    Returns a dataframe of the historical adjusted close prices of the assets.\n",
        "    - Only one method of date input should be provided, either 'period' or 'start_date' and 'end_date'.\n",
        "    - Length of time series should be large enough to handle metric calculations.\n",
        "\n",
        "    Parameters:\n",
        "    - period: yfinance time period (e.g., '3mo', '1y', '3y', '5y', 'ytd', 'max').\n",
        "    - start_date: Start date of the time series. YYYY-MM-DD format.\n",
        "    - end_date: End date of the time series. YYYY-MM-DD format.\n",
        "    \"\"\"\n",
        "    try:\n",
        "      if period and (start_date or end_date): #checks if both methods of date input are used\n",
        "        raise ValueError(\"Provide either 'period' OR both 'start_date' and 'end_date' -- not both.\")\n",
        "\n",
        "      if period:\n",
        "        period = period.strip()\n",
        "        self.dfclose = yf.download(self.portfolio, period=period, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "      elif start_date and end_date:\n",
        "        start_date = start_date.strip()\n",
        "        end_date = end_date.strip()\n",
        "        self.dfclose = yf.download(self.portfolio, start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "      else:\n",
        "        raise ValueError(\"You must provide either a 'period' or both 'start_date' and 'end_date'.\")\n",
        "\n",
        "      if self.dfclose.empty or self.dfclose is None:\n",
        "        raise ValueError(\"Downloaded price data is empty or unavailable.\")\n",
        "      elif len(self.dfclose) <= 2:\n",
        "        raise ValueError(\"Downloaded price data is too short.\")\n",
        "      elif len(self.dfclose) < 21: #average trading days in a month\n",
        "        print(\"Warning: Limited price history may lead to unreliable metrics.\")\n",
        "\n",
        "      return self.dfclose\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in get_data: {e}\")\n",
        "      return None\n",
        "\n",
        "  def get_weights(self, type_weight:str):\n",
        "    \"\"\"\n",
        "    Returns a list of weights for the portfolio.\n",
        "\n",
        "    Parameters:\n",
        "    - type_weight: Input 'eq' for equal-weighted portfolio or 'opt' for optimized weights based on the Sharpe-Ratio\n",
        "    \"\"\"\n",
        "    try:\n",
        "      dfclose = self.dfclose\n",
        "      if dfclose is None or dfclose.empty:\n",
        "        raise ValueError(\"The portfolio's price data is missing. Please properly run 'get_data' first.\")\n",
        "      elif len(dfclose) <= 2:\n",
        "        raise ValueError(\"Downloaded price data is too short.\")\n",
        "\n",
        "      #Get log returns of each asset\n",
        "      log_returns = np.log(dfclose/dfclose.shift()).dropna()\n",
        "\n",
        "      #Calculate initial portfolio metrics\n",
        "      weights = np.repeat(1/len(self.portfolio), len(self.portfolio))\n",
        "      expected_returns = log_returns.mean()*252\n",
        "      port_returns = weights.T @ expected_returns\n",
        "      cov_matrix = log_returns.cov()*252\n",
        "      port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
        "      rf = 0.045\n",
        "\n",
        "      #Set bounds and constraints for objective function\n",
        "      bounds = [(self.lower_bound, self.upper_bound) for _ in range(len(self.portfolio))]\n",
        "      constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w)-1}\n",
        "      def neg_sharpe(w):\n",
        "        port_ret = w.T @ expected_returns\n",
        "        port_std = np.sqrt(w.T @ cov_matrix @ w)\n",
        "        return -((port_ret - rf)/port_std)\n",
        "\n",
        "      if type_weight.strip().lower() == \"eq\":\n",
        "        self.weights = [float(i) for i in weights]\n",
        "      elif type_weight.strip().lower() == \"opt\":\n",
        "        optimized_weights = minimize(neg_sharpe, weights, method=\"SLSQP\", bounds=bounds, constraints=constraints)\n",
        "        self.weights = [round(float(i),4) for i in optimized_weights.x]\n",
        "      else:\n",
        "        raise ValueError(\"Select a valid input for 'type_weight' -- either 'eq' or 'opt'.\")\n",
        "\n",
        "      return self.weights\n",
        "\n",
        "    except Exception as e:\n",
        "      print(f\"Error in get_weights: {e}\")\n",
        "      return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrPonahsNZiJ",
        "outputId": "64abc5c7-a2ca-43e2-f7ff-9d3206b7cf88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.3106, 0.0766, 0.1128, 0.5, 0.0]"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#test weights\n",
        "test = Portfolio([\"AAPL\", \"MSFT\", \"GOOG\", \"JNJ\", \"XOM\"], 0.0, 0.5)\n",
        "test.get_data('10y')\n",
        "test.get_weights(\"opt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nz7s7C0VPA00"
      },
      "outputs": [],
      "source": [
        "def monte_carlo(T:int, sims:int, weights:list, df:pd.DataFrame, regime:str, level:str, factorReturns:list=None, rand:bool=None ):\n",
        "  \"\"\"\n",
        "  Returns simulated portfolio returns using Monte Carlo Simulation.\n",
        "\n",
        "  Parameters:\n",
        "  - T: Number of days in each simulation.\n",
        "  - sims: Number of simulations.\n",
        "  - weights: List of asset weights.\n",
        "  - df: Dataframe of the historical adjusted close prices of the assets.\n",
        "  - regime: Determines how much or how little the portfolio is affected by the crisis event.   \n",
        "  - level: Scale of the crisis event.\n",
        "  - \n",
        "  - rand: input the boolean 'True' to return a random simulation, otherwise ignore\n",
        "\n",
        "    regime options: 'Low', 'Medium', 'High'\n",
        "    level options: 'Mild', 'Moderate', 'Severe', 'Tail Risk', 'Regulatory'\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if T <= 2:\n",
        "      raise ValueError(\"The length of each simulated path is too short.\")\n",
        "    elif T < 21:\n",
        "      print(\"Warning: Limited price data may lead to unreliable metrics.\")\n",
        "\n",
        "    #Intialize dictionary to store simulated paths of T days for each ticker\n",
        "    tickers = list(df.columns) + ['SPY']\n",
        "    weights = weights + [0.000]\n",
        "    sims_returns = {ticker: np.full(shape=(T, sims), fill_value=0.0) for ticker in tickers}\n",
        "    \n",
        "    #Correspond regime with scaling factor\n",
        "    regime = regime.strip().capitalize()\n",
        "    level = level.strip().capitalize()\n",
        "    factorDict = {\"Mild\": 1.0,\n",
        "                  \"Moderate\": 1.3,\n",
        "                  \"Severe\": 1.7,\n",
        "                  \"Tail risk\": 2.0,\n",
        "                  \"Regulatory\": 2.5}\n",
        "    scaling_factor = factorDict[level]\n",
        "\n",
        "    #Calculate log returns and align with market returns\n",
        "    start_date = pd.to_datetime(df.index[0])\n",
        "    end_date = pd.to_datetime(df.index[-1])\n",
        "    market = yf.download('SPY', start=start_date, end=end_date, progress=False, auto_adjust=False)['Adj Close']\n",
        "    market_returns = np.log(market/market.shift()).dropna()\n",
        "    log_returns = np.log(df/df.shift()).dropna()\n",
        "    aligned_index = log_returns.index.intersection(market_returns.index)\n",
        "    market_returns = market_returns.loc[aligned_index]\n",
        "    log_returns = log_returns.loc[aligned_index]\n",
        "    log_returns['SPY'] = market_returns\n",
        "\n",
        "    #Create mean matrix \n",
        "    if factorReturns is not None:\n",
        "      meanM = np.full(shape=(T, len(tickers)), fill_value=factorReturns)\n",
        "    else:\n",
        "      expected_return = log_returns.mean()\n",
        "      meanM = np.full(shape=(T, len(tickers)), fill_value=expected_return)\n",
        "\n",
        "    #Initalize HMM\n",
        "    port_returns = (log_returns @ weights).values.reshape(-1,1) #HMM requires 2D array\n",
        "    historical_port_vol = np.std(port_returns)\n",
        "    model = GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=1000, random_state=42)\n",
        "    model.fit(port_returns)\n",
        "\n",
        "    #Gather the volatility regimes established by the HMM and correspond them with their respective state\n",
        "    vol_states = [\"Low\",\"Medium\",\"High\"]\n",
        "    vol_regimes = np.sqrt([var[0][0] for var in model.covars_])\n",
        "    vol_regimes = np.sort(vol_regimes)\n",
        "    vol_dict = {state: vol for state, vol in zip(vol_states, vol_regimes)}\n",
        "\n",
        "    #Calculate the scale factor needed for the historical data to reach the desired volatility and then apply it to L\n",
        "    desired_vol = vol_dict[regime]*scaling_factor\n",
        "    vol_scale_factor = desired_vol / historical_port_vol\n",
        "    cov_matrix = log_returns.cov()* (vol_scale_factor**2)\n",
        "    L = np.linalg.cholesky(cov_matrix)\n",
        "\n",
        "    #Generate paths\n",
        "    for m in range(sims):\n",
        "      Z = np.random.normal(size=(T, len(tickers)))\n",
        "      dailyReturns = meanM + Z @ L.T\n",
        "      for i, ticker in enumerate(tickers):\n",
        "        sims_returns[ticker][:,m] = dailyReturns[:,i]\n",
        "\n",
        "    #Get a random path\n",
        "    if rand:\n",
        "      random_int = np.random.randint(0,sims)\n",
        "      random_sims_returns = {ticker: sims_returns[ticker][:,random_int] for ticker in tickers}\n",
        "      random_sims_df = pd.DataFrame(random_sims_returns)\n",
        "      return random_sims_df\n",
        "    elif rand != None:\n",
        "      raise ValueError(\"Invaild input for 'rand'. Input the string 'yes' to return a random path, otherwise ignore.\")\n",
        "    else:\n",
        "        return sims_returns\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in monte_carlo: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AAPL</th>\n",
              "      <th>GOOG</th>\n",
              "      <th>JNJ</th>\n",
              "      <th>MSFT</th>\n",
              "      <th>XOM</th>\n",
              "      <th>SPY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.011233</td>\n",
              "      <td>0.007702</td>\n",
              "      <td>0.003213</td>\n",
              "      <td>0.007368</td>\n",
              "      <td>-0.008796</td>\n",
              "      <td>-0.003690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.023796</td>\n",
              "      <td>-0.018434</td>\n",
              "      <td>0.004512</td>\n",
              "      <td>-0.020335</td>\n",
              "      <td>0.000869</td>\n",
              "      <td>-0.007726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.020312</td>\n",
              "      <td>-0.027898</td>\n",
              "      <td>0.015285</td>\n",
              "      <td>-0.026217</td>\n",
              "      <td>-0.007628</td>\n",
              "      <td>-0.013072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.003836</td>\n",
              "      <td>0.007549</td>\n",
              "      <td>-0.001014</td>\n",
              "      <td>-0.001690</td>\n",
              "      <td>-0.035535</td>\n",
              "      <td>-0.007008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.007277</td>\n",
              "      <td>-0.004699</td>\n",
              "      <td>0.001178</td>\n",
              "      <td>-0.001735</td>\n",
              "      <td>0.002038</td>\n",
              "      <td>-0.000686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.006275</td>\n",
              "      <td>0.009345</td>\n",
              "      <td>-0.007587</td>\n",
              "      <td>0.000531</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.001013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.002775</td>\n",
              "      <td>-0.004645</td>\n",
              "      <td>-0.008180</td>\n",
              "      <td>-0.007393</td>\n",
              "      <td>-0.012840</td>\n",
              "      <td>-0.003766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.000815</td>\n",
              "      <td>0.018523</td>\n",
              "      <td>-0.006021</td>\n",
              "      <td>-0.013282</td>\n",
              "      <td>0.015894</td>\n",
              "      <td>-0.003937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.030708</td>\n",
              "      <td>0.010986</td>\n",
              "      <td>0.001723</td>\n",
              "      <td>0.036041</td>\n",
              "      <td>-0.004538</td>\n",
              "      <td>0.018695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.028279</td>\n",
              "      <td>0.033311</td>\n",
              "      <td>-0.004992</td>\n",
              "      <td>0.026799</td>\n",
              "      <td>-0.002451</td>\n",
              "      <td>0.013532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.020263</td>\n",
              "      <td>-0.013945</td>\n",
              "      <td>-0.007823</td>\n",
              "      <td>-0.029142</td>\n",
              "      <td>0.007242</td>\n",
              "      <td>-0.012461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>-0.001451</td>\n",
              "      <td>-0.012822</td>\n",
              "      <td>0.006428</td>\n",
              "      <td>0.002843</td>\n",
              "      <td>-0.011557</td>\n",
              "      <td>0.002448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.016881</td>\n",
              "      <td>0.015001</td>\n",
              "      <td>-0.014753</td>\n",
              "      <td>0.004337</td>\n",
              "      <td>0.002310</td>\n",
              "      <td>0.008106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.004878</td>\n",
              "      <td>-0.010717</td>\n",
              "      <td>-0.002060</td>\n",
              "      <td>-0.016852</td>\n",
              "      <td>-0.008772</td>\n",
              "      <td>-0.004807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>-0.004706</td>\n",
              "      <td>0.026266</td>\n",
              "      <td>0.002634</td>\n",
              "      <td>0.007084</td>\n",
              "      <td>0.021143</td>\n",
              "      <td>0.017304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>-0.003659</td>\n",
              "      <td>0.010822</td>\n",
              "      <td>0.011413</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>-0.012564</td>\n",
              "      <td>-0.003870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.010097</td>\n",
              "      <td>0.007452</td>\n",
              "      <td>0.012936</td>\n",
              "      <td>0.007616</td>\n",
              "      <td>-0.010384</td>\n",
              "      <td>0.004052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.039252</td>\n",
              "      <td>0.046014</td>\n",
              "      <td>0.011603</td>\n",
              "      <td>0.034903</td>\n",
              "      <td>-0.001305</td>\n",
              "      <td>0.028518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.001140</td>\n",
              "      <td>-0.008493</td>\n",
              "      <td>0.008691</td>\n",
              "      <td>-0.012456</td>\n",
              "      <td>0.017497</td>\n",
              "      <td>0.001296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>-0.000591</td>\n",
              "      <td>-0.000005</td>\n",
              "      <td>-0.002709</td>\n",
              "      <td>0.010454</td>\n",
              "      <td>-0.019081</td>\n",
              "      <td>0.003111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.000931</td>\n",
              "      <td>0.006969</td>\n",
              "      <td>0.007712</td>\n",
              "      <td>0.009467</td>\n",
              "      <td>-0.015631</td>\n",
              "      <td>0.008448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>-0.010198</td>\n",
              "      <td>0.006760</td>\n",
              "      <td>0.007479</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>0.020108</td>\n",
              "      <td>0.001206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>-0.004214</td>\n",
              "      <td>0.004046</td>\n",
              "      <td>0.014749</td>\n",
              "      <td>0.000269</td>\n",
              "      <td>-0.008838</td>\n",
              "      <td>-0.009545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.021277</td>\n",
              "      <td>0.003041</td>\n",
              "      <td>0.002823</td>\n",
              "      <td>0.015345</td>\n",
              "      <td>0.007333</td>\n",
              "      <td>0.008150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.005843</td>\n",
              "      <td>-0.002460</td>\n",
              "      <td>-0.016214</td>\n",
              "      <td>-0.010268</td>\n",
              "      <td>0.001765</td>\n",
              "      <td>0.000823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        AAPL      GOOG       JNJ      MSFT       XOM       SPY\n",
              "0  -0.011233  0.007702  0.003213  0.007368 -0.008796 -0.003690\n",
              "1  -0.023796 -0.018434  0.004512 -0.020335  0.000869 -0.007726\n",
              "2  -0.020312 -0.027898  0.015285 -0.026217 -0.007628 -0.013072\n",
              "3  -0.003836  0.007549 -0.001014 -0.001690 -0.035535 -0.007008\n",
              "4   0.007277 -0.004699  0.001178 -0.001735  0.002038 -0.000686\n",
              "5   0.006275  0.009345 -0.007587  0.000531  0.005600  0.001013\n",
              "6   0.002775 -0.004645 -0.008180 -0.007393 -0.012840 -0.003766\n",
              "7  -0.000815  0.018523 -0.006021 -0.013282  0.015894 -0.003937\n",
              "8   0.030708  0.010986  0.001723  0.036041 -0.004538  0.018695\n",
              "9   0.028279  0.033311 -0.004992  0.026799 -0.002451  0.013532\n",
              "10 -0.020263 -0.013945 -0.007823 -0.029142  0.007242 -0.012461\n",
              "11 -0.001451 -0.012822  0.006428  0.002843 -0.011557  0.002448\n",
              "12  0.016881  0.015001 -0.014753  0.004337  0.002310  0.008106\n",
              "13  0.004878 -0.010717 -0.002060 -0.016852 -0.008772 -0.004807\n",
              "14 -0.004706  0.026266  0.002634  0.007084  0.021143  0.017304\n",
              "15 -0.003659  0.010822  0.011413  0.012018 -0.012564 -0.003870\n",
              "16  0.010097  0.007452  0.012936  0.007616 -0.010384  0.004052\n",
              "17  0.039252  0.046014  0.011603  0.034903 -0.001305  0.028518\n",
              "18  0.001140 -0.008493  0.008691 -0.012456  0.017497  0.001296\n",
              "19 -0.000591 -0.000005 -0.002709  0.010454 -0.019081  0.003111\n",
              "20  0.000931  0.006969  0.007712  0.009467 -0.015631  0.008448\n",
              "21 -0.010198  0.006760  0.007479  0.002007  0.020108  0.001206\n",
              "22 -0.004214  0.004046  0.014749  0.000269 -0.008838 -0.009545\n",
              "23  0.021277  0.003041  0.002823  0.015345  0.007333  0.008150\n",
              "24  0.005843 -0.002460 -0.016214 -0.010268  0.001765  0.000823"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = test.get_data('5y')\n",
        "monte_carlo(T=25, sims=5, weights=[0.0, 0.0596, 0.0, 0.4404, 0.5], df=df, regime=\"Low\", level='Mild', rand=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBjYP6uUOuJy"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(weights:list, df:pd.DataFrame):\n",
        "  \"\"\"\n",
        "  Calculates the metrics and the percent contribution of risk for each stock in the portfolio.\n",
        "  - Metrics returned: Annual portfolio volatilty, Sharpe Ratio, 95% VaR, 95% CVaR, Max Drawdown, and Beta.\n",
        "\n",
        "  Parameters:\n",
        "  - weights: List of each assets weight in the portfolio\n",
        "  - df: Dataframe of the historical adjusted close prices of the assets or simulated returns via the monte_carlo function\n",
        "  \"\"\"\n",
        "  try:\n",
        "    if df is None or df.empty:\n",
        "      raise ValueError(\"Price data is empty or unavailable. Make sure historical/simulated data is properly downloaded.\")\n",
        "\n",
        "    #Core calculations\n",
        "    if df.iloc[0,0] < 1:\n",
        "      log_returns = df\n",
        "      weights = weights + [0.000]\n",
        "    else:\n",
        "      log_returns = np.log(df/df.shift()).dropna()\n",
        "\n",
        "    tickers = list(df.columns)\n",
        "    weights = np.array(weights)\n",
        "    expected_returns = log_returns.mean()*252\n",
        "    cov_matrix = log_returns.cov()*252\n",
        "    rf = 0.045\n",
        "    port_returns = weights.T @ expected_returns\n",
        "    port_returns_series = log_returns @ weights\n",
        "\n",
        "    #Metrics\n",
        "    port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
        "    sharpe = (port_returns - rf)/port_vol\n",
        "    VaR_95 = np.percentile(port_returns_series, 5)\n",
        "    CVaR_95 = port_returns_series[port_returns_series <= VaR_95].mean()\n",
        "\n",
        "    #Max Drawdown\n",
        "    cum_returns = (1+port_returns_series).cumprod()\n",
        "    cum_max = np.maximum.accumulate(cum_returns)\n",
        "    drawdown = cum_returns/cum_max - 1\n",
        "    mdd = drawdown.min() #drawdown values are negative\n",
        "\n",
        "    #Beta\n",
        "    if pd.api.types.is_integer_dtype(port_returns_series.index):\n",
        "      #Simulated case: align by length\n",
        "      market_returns = df['SPY']\n",
        "    else:\n",
        "      market = yf.download(\"SPY\", period='max', progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "      market_returns = (np.log(market/market.shift()).dropna()).squeeze() #convert to series so that it works properly with port_returns_series\n",
        "      \n",
        "      #Simulated historical case: align by date\n",
        "      start_date = pd.to_datetime(port_returns_series.index[0])\n",
        "      end_date = pd.to_datetime(port_returns_series.index[-1])\n",
        "      if start_date and end_date not in market_returns.index: #first make sure that market data contains crisis event\n",
        "        market = yf.download(\"SPY\", start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "        market_returns = (np.log(market/market.shift()).dropna()).squeeze()\n",
        "\n",
        "      #align by date for either simulated historical or historical case\n",
        "      aligned_index = port_returns_series.index.intersection(market_returns.index)\n",
        "      market_returns = market_returns.loc[aligned_index]\n",
        "      port_returns_series = port_returns_series.loc[aligned_index]\n",
        "    beta = port_returns_series.cov(market_returns) / market_returns.var()\n",
        "\n",
        "    #Calculate PCR (Percent Contribution to Risk)\n",
        "    PCRdict = {}\n",
        "    if 'SPY' in tickers:\n",
        "      tickers = tickers[:-1] #Remove 'SPY' \n",
        "      weights = weights[:-1]\n",
        "    for i, ticker in enumerate(tickers):\n",
        "      ticker_vol = np.std(log_returns[ticker]) * np.sqrt(252)\n",
        "      ticker_corr = log_returns[ticker].corr(port_returns_series)\n",
        "      MRC = ticker_vol*ticker_corr\n",
        "      PCR = (weights[i]*MRC)/port_vol\n",
        "      PCRdict[ticker] = (f\"{PCR*100:.2f}%\")\n",
        "    PCRframe = pd.DataFrame(data=PCRdict, index=[\"PCR\"])\n",
        "\n",
        "    metrics = pd.DataFrame(data=[[port_vol, sharpe, VaR_95, CVaR_95, mdd, beta]] ,columns=[\"Annual Volatilty\", \"Sharpe\",\"95% VaR\", \"95% CVaR\", \"Max DD\", \"Beta\"], index=[\"Portfolio\"])\n",
        "    return metrics, PCRframe\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\"Error in calculate_metrics: {e}\")\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 417,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(           Annual Volatilty    Sharpe   95% VaR  95% CVaR    Max DD     Beta\n",
              " Portfolio          0.470834 -2.919566 -0.047641 -0.076213 -0.527386  1.19959,\n",
              "        AAPL   AMZN    GOOG    META\n",
              " PCR  32.16%  0.00%  46.77%  20.58%)"
            ]
          },
          "execution_count": 417,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = test.get_data('5y')\n",
        "rand = monte_carlo(100,100,[0.353, 0.0, 0.4469, 0.2001], df, 'Medium', 'Tail risk', rand=True)\n",
        "calculate_metrics([0.353, 0.0, 0.4469, 0.2001], rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 415,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPEDH1CnO54O",
        "outputId": "d87de544-986b-4ba1-fea5-9e7f73836edd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 Annual Volatilty    Sharpe  95% VaR    Max DD      Beta\n",
            "Worst Portfolio          0.579095 -1.586592 -0.06329 -0.887424  1.176545\n",
            "       AAPL   AMZN    GOOG    META\n",
            "PCR  31.98%  0.00%  44.12%  23.81%\n",
            "                Annual Volatilty    Sharpe   95% VaR    Max DD      Beta\n",
            "Best Portfolio           0.56331  2.447176 -0.053075 -0.367143  1.172476\n",
            "       AAPL   AMZN    GOOG    META\n",
            "PCR  33.08%  0.00%  42.89%  23.94%\n"
          ]
        }
      ],
      "source": [
        "#test the simulated max and min sharpe metrics\n",
        "df = test.get_data('10y')\n",
        "mc = monte_carlo(504,50,[0.353, 0.0, 0.4469, 0.2001], df, regime=\"High\", level='Moderate')\n",
        "tickers = list(df.columns) + ['SPY']\n",
        "sims = len(mc[tickers[0]][0])\n",
        "all_metrics = []\n",
        "all_PCR = []\n",
        "for m in range(sims):\n",
        "  mth_df = pd.DataFrame({ticker: mc[ticker][:,m] for ticker in tickers})\n",
        "  metrics = calculate_metrics([0.353, 0.0, 0.4469, 0.2001], mth_df)\n",
        "  all_metrics.append(metrics[0])\n",
        "  all_PCR.append(metrics[1])\n",
        "sharpes = [df.loc[\"Portfolio\", \"Sharpe\"] for df in all_metrics]\n",
        "min_idx = np.argmin(sharpes)\n",
        "max_idx = np.argmax(sharpes)\n",
        "all_metrics[min_idx].index = [\"Worst Portfolio\"]\n",
        "all_metrics[max_idx].index = [\"Best Portfolio\"]\n",
        "print(all_metrics[min_idx])\n",
        "print(all_PCR[min_idx])\n",
        "print(all_metrics[max_idx])\n",
        "print(all_PCR[max_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhhEAq3-SESm"
      },
      "outputs": [],
      "source": [
        "def historical(df:pd.DataFrame, crisis:str):\n",
        "  \"\"\"\n",
        "  Returns the prices of your portfolio if during a historical crisis event.\n",
        "  \n",
        "  Parameters:\n",
        "  - df: Dataframe of the historical adjusted close prices of the assets.\n",
        "  - crisis: String of the event you want to simulate.\n",
        "\n",
        "    Crisis Options:\n",
        "    - \"DOT-COM\" -- The Dot-Com bubble\n",
        "    - \"2008 GFC\" -- 2008 Global Financial Crisis\n",
        "    - \"2011 Euro\" -- 2011 Eurozone Crisis\n",
        "    - \"COVID\" -- COVID-19 Pandemic\n",
        "    - \"2022 Inf\" -- 2022 Inflation Crash\n",
        "  \"\"\"\n",
        "  try:\n",
        "    crisis_periods = {\"DOT-COM\": (\"2000-03-01\", \"2002-10-01\"),\n",
        "                      \"2008 GFC\": (\"2007-10-01\", \"2009-03-01\"),\n",
        "                      \"2011 Euro\": (\"2011-07-01\", \"2011-12-01\"),\n",
        "                      \"COVID\": (\"2020-02-14\", \"2020-04-15\"),\n",
        "                      \"2022 Inf\": (\"2022-01-01\", \"2022-10-01\")\n",
        "                      }\n",
        "    crisis = crisis.strip()\n",
        "    if crisis not in crisis_periods.keys():\n",
        "      raise ValueError(\"Input a valid crisis event.\")\n",
        "\n",
        "    tickers = list(df.columns)\n",
        "    start_date = pd.to_datetime(crisis_periods[crisis][0])\n",
        "    end_date = pd.to_datetime(crisis_periods[crisis][1])\n",
        "\n",
        "    if start_date not in df.index: #check if crisis event does not exist in existing df\n",
        "      dfcrisis = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=False)[\"Adj Close\"]\n",
        "    else:\n",
        "      dfcrisis = df.loc[start_date:end_date]\n",
        "\n",
        "    for ticker in tickers:\n",
        "      if dfcrisis[ticker].isna().sum() >= len(dfcrisis[ticker])//3: #checks if any ticker reaches NA threshold\n",
        "        raise ValueError(f\"{ticker} price data does not exist for crisis period.\")\n",
        "\n",
        "    last_price = df.iloc[-1]\n",
        "    crisisReturns = np.log(dfcrisis/dfcrisis.shift()).dropna()\n",
        "    cumReturns = (1+crisisReturns).cumprod()\n",
        "    crisisPrices = last_price.mul(cumReturns)\n",
        "    return crisisPrices\n",
        "\n",
        "  except Exception as e:\n",
        "    print(f\" \\n Error in historical: {e}\")\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "id": "B-qNv5CHoCLc",
        "outputId": "bb59e533-9814-4e1b-fff4-ca13596e8713"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(           Annual Volatilty    Sharpe   95% VaR  95% CVaR    Max DD      Beta\n",
              " Portfolio          0.829948 -2.356408 -0.106502 -0.126618 -0.439156  1.097892,\n",
              "       AAPL   GOOG    JNJ    MSFT     XOM\n",
              " PCR  0.00%  4.41%  0.00%  44.53%  49.81%)"
            ]
          },
          "execution_count": 422,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = yf.download([\"AAPL\", \"MSFT\", \"GOOG\", \"JNJ\", \"XOM\"], period='10y', auto_adjust=False)[\"Adj Close\"]\n",
        "hist = historical(df, \"COVID\")\n",
        "calculate_metrics([0.0, 0.056, 0.0, 0.444, 0.5], hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def factor_stress(df:pd.DataFrame, factor_dict:dict):\n",
        "    \"\"\"\n",
        "    Computes stressed expected returns for each asset in the portfolio using a multi-factor model \n",
        "    and user-defined shocks to the factor premia.\n",
        "\n",
        "    Parameters:\n",
        "    - df: Dataframe of the historical adjusted close prices of the assets.\n",
        "    - factor_dict: Dictionary of factor names and their respective shocks (e.g., {'SMB': 0.4, 'HML': -0.2}).\n",
        "      = If 'FF3' or 'FF5' is entered as a key, either apply independent shocks via list or a single float for a constant shock as the value.\n",
        "\n",
        "      factor options:\n",
        "      - 'FF3' = Fama-French 3-Research Factors: ['Mkt-RF', 'SMB', 'HML']\n",
        "      - 'FF5' = Fama-French 5-Research Factors: ['Mkt-RF', 'SMB', 'HML', 'RMW', 'CMA']\n",
        "      - 'Mkt-RF' = Market Returns - Risk-Free-Rate: Market Risk Premium.\n",
        "      - 'SMB' = Small Minus Big: Returns of small-cap stocks minus large-cap stocks; measures the size anomaly - small-cap tend to outperform.\n",
        "      - 'HML' = High Minus Low: Returns of high B/M (value) stocks minus low B/M (growth) stocks; measures the value anomaly - value stocks tend to outperform.\n",
        "      - 'RMW' = Robust Minus Weak: Returns of firms with robust profability minus those with weak profitability; measures profitability factor - more robust firms tend to earn higher returns.\n",
        "      - 'CMA' = Conservative Minus Aggressive: Returns of firms with conservative investment minus aggressive policies; captures investment factor - conservative tend to perform better.\n",
        "      - 'MOM' = Momentum: Returns of stocks with high prior returns minus those with low prior returns; captures the momentum effect where past winners tend to continue outperforming in the short term.\n",
        "\n",
        "      The user can input any combination of these factors that they desire.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if 'FF3' in factor_dict.keys():\n",
        "            FF3_value = factor_dict.pop('FF3')\n",
        "            if len(FF3_value) not in [1,3]:\n",
        "                raise ValueError(\"Invalid shock length for 'FF3'. Either input a float for a uniform shock or a list of independent shocks for each factor.\")\n",
        "\n",
        "            if isinstance(FF3_value, list): #Unique shocks per factor in 'FF3'\n",
        "                factor_dict.update({\n",
        "                    'Mkt-RF': FF3_value[0],\n",
        "                    'SMB': FF3_value[1],\n",
        "                    'HML': FF3_value[2]\n",
        "                    })\n",
        "            else: #Uniform shock to all factors in 'FF3'\n",
        "                factor_dict.update({\n",
        "                    'Mkt-RF': FF3_value,\n",
        "                    'SMB': FF3_value,\n",
        "                    'HML': FF3_value\n",
        "                    })\n",
        "        elif 'FF5' in factor_dict.keys():\n",
        "            FF5_value = factor_dict.pop('FF5')\n",
        "            if isinstance(FF5_value, list): #Unique shocks per factor in 'FF5'\n",
        "                factor_dict.update({\n",
        "                    'Mkt-RF': FF5_value[0],\n",
        "                    'SMB': FF5_value[1],\n",
        "                    'HML': FF5_value[2],\n",
        "                    'RMW': FF5_value[3],\n",
        "                    'CMA': FF5_value[4]\n",
        "                    })\n",
        "            else: #Uniform shock to all factors in 'FF5'\n",
        "                factor_dict.update({\n",
        "                    'Mkt-RF': FF5_value,\n",
        "                    'SMB': FF5_value,\n",
        "                    'HML': FF5_value,\n",
        "                    'RMW': FF5_value,\n",
        "                    'CMA': FF5_value\n",
        "                    })\n",
        "            \n",
        "        factors = list(factor_dict.keys())\n",
        "        shocks = list(factor_dict.values())\n",
        "\n",
        "        #Read and clean factor csvs\n",
        "        FFdf = pd.read_csv('../data/F-F_Research_Data_5_Factors_2x3_daily.csv', skiprows=3, index_col=0)\n",
        "        FFdf = FFdf.iloc[:-1]\n",
        "        FFdf.index = pd.to_datetime(FFdf.index)\n",
        "        MOMdf = pd.read_csv('../data/F-F_Momentum_Factor_daily.csv', skiprows=13, index_col=0)\n",
        "        MOMdf = MOMdf.rename(columns={'Mom':'MOM'})\n",
        "        MOMdf = MOMdf.iloc[:-1]\n",
        "        MOMdf.index = pd.to_datetime(MOMdf.index)\n",
        "\n",
        "        #Align both factor csvs and only grab necessary factors\n",
        "        factor_align = MOMdf.index.intersection(FFdf.index)\n",
        "        FFdf = FFdf.loc[factor_align]\n",
        "        MOMdf = MOMdf.loc[factor_align]\n",
        "        factors_df = pd.concat([FFdf, MOMdf], axis=1)\n",
        "        rf = factors_df['RF'].copy()\n",
        "        factors_df = factors_df.loc[:, factors]\n",
        "        \n",
        "        #Align historical asset returns with joint factor df\n",
        "        log_returns = np.log(df/df.shift()).dropna()\n",
        "        aligned_index = log_returns.index.intersection(factors_df.index) \n",
        "        log_returns = log_returns.loc[aligned_index]\n",
        "        factors_df = factors_df.loc[aligned_index]/100\n",
        "        factor_means = factors_df.mean()\n",
        "        rf = rf.loc[aligned_index]/100\n",
        "\n",
        "        #Fit OLS on each ticker and store neccesary values\n",
        "        results = {}\n",
        "        stressed_means = {}\n",
        "        tickers = list(df.columns)\n",
        "        for ticker in tickers:\n",
        "            excess_returns = log_returns[ticker] - rf\n",
        "            X = sm.add_constant(factors_df)\n",
        "            y = excess_returns\n",
        "\n",
        "            model = sm.OLS(y, X).fit()\n",
        "            results[ticker] = {\n",
        "                'alpha': model.params['const'],\n",
        "                'betas': model.params.drop('const').to_dict(),\n",
        "                'r-squared': model.rsquared\n",
        "            }\n",
        "            #Compute stressed mean returns\n",
        "            alpha = results[ticker]['alpha']\n",
        "            betas = results[ticker]['betas']\n",
        "            stressed_mean = alpha\n",
        "            for factor in factors:\n",
        "                stressed_mean += betas[factor]*factor_means[factor]*(1+factor_dict[factor])\n",
        "            stressed_means[ticker] = stressed_mean\n",
        "        stressed_means['SPY'] = 0.0\n",
        "        stressed_means_list = list(map(float, list(stressed_means.values())))\n",
        "\n",
        "        return stressed_means_list\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in factor_stress: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(           Annual Volatilty    Sharpe  95% VaR  95% CVaR    Max DD      Beta\n",
              " Portfolio           0.45551 -3.994335 -0.05634 -0.059835 -0.261543  1.218546,\n",
              "       AAPL   GOOG    JNJ    MSFT     XOM\n",
              " PCR  0.00%  4.41%  0.00%  37.14%  56.43%)"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = test.get_data('5y')\n",
        "factors = factor_stress(df, {'FF3': [0, 0.2, 0.1], 'MOM': -0.4})\n",
        "sim = monte_carlo(T=25, sims=5, weights=[0.0, 0.0596, 0.0, 0.4404, 0.5], df=df, regime=\"Low\", level='Regulatory', factorReturns=factors, rand=True)\n",
        "calculate_metrics([0.0, 0.0596, 0.0, 0.4404, 0.5], sim)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMjeGxU8gQJHS+IGNW8Vz1s",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
